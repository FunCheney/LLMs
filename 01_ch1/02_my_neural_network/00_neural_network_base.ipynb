{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-18T12:21:27.765096Z",
     "start_time": "2025-08-18T12:21:26.872199Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 定义一个输入层到隐藏层的全连接层\n",
    "        self.fc1 = nn.Linear(2, 2)  # 输入 2 个特征，输出 2 个特征\n",
    "        # 定义一个隐藏层到输出层的全连接层\n",
    "        self.fc2 = nn.Linear(2, 1)  # 输入 2 个特征，输出 1 个预测值\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播过程\n",
    "        x = torch.relu(self.fc1(x))  # 使用 ReLU 激活函数\n",
    "        x = self.fc2(x)  # 输出层\n",
    "        return x\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleNN()\n",
    "\n",
    "model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### PyTorch 提供了许多常见的神经网络层，以下是几个常见的：\n",
    "\n",
    "* nn.Linear(in_features, out_features)：全连接层，输入 in_features 个特征，输出 out_features 个特征。\n",
    "* nn.Conv2d(in_channels, out_channels, kernel_size)：2D 卷积层，用于图像处理。\n",
    "* nn.MaxPool2d(kernel_size)：2D 最大池化层，用于降维。\n",
    "* nn.ReLU()：ReLU 激活函数，常用于隐藏层。\n",
    "* nn.Softmax(dim)：Softmax 激活函数，通常用于输出层，适用于多类分类问题。"
   ],
   "id": "57394e376472857a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 激活函数（Activation Function）\n",
    "激活函数决定了神经元是否应该被激活。它们是非线性函数，使得神经网络能够学习和执行更复杂的任务。常见的激活函数包括：\n",
    "\n",
    "* Sigmoid：用于二分类问题，输出值在 0 和 1 之间。\n",
    "* Tanh：输出值在 -1 和 1 之间，常用于输出层之前。\n",
    "* ReLU（Rectified Linear Unit）：目前最流行的激活函数之一，定义为 f(x) = max(0, x)，有助于解决梯度消失问题。\n",
    "* Softmax：常用于多分类问题的输出层，将输出转换为概率分布"
   ],
   "id": "a28e352236979b53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:48:44.636159Z",
     "start_time": "2025-08-19T08:48:44.626444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = torch.randn(3, 4)\n",
    "input"
   ],
   "id": "8da5dd2614713e31",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1379, -0.1032,  0.6595,  1.4069],\n",
       "        [ 1.5622,  0.6512, -0.7125, -0.4220],\n",
       "        [-0.9806,  0.7302,  0.6728,  0.4321]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:48:10.946269Z",
     "start_time": "2025-08-19T08:48:10.929939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "output = F.relu(input)\n",
    "output"
   ],
   "id": "ffdf6557071219c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3437, 0.9957, 0.4564, 0.1309],\n",
       "        [0.0000, 0.0000, 0.0000, 0.4279],\n",
       "        [0.0891, 1.3674, 0.6743, 0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:48:17.815862Z",
     "start_time": "2025-08-19T08:48:17.811824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = F.sigmoid(input)\n",
    "output"
   ],
   "id": "96bd39cf437cae2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7931, 0.7302, 0.6122, 0.5327],\n",
       "        [0.2456, 0.2002, 0.2858, 0.6054],\n",
       "        [0.5223, 0.7970, 0.6625, 0.1152]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:48:21.991001Z",
     "start_time": "2025-08-19T08:48:21.987292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = F.tanh(input)\n",
    "output"
   ],
   "id": "614e175e9f9ee281",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8726,  0.7598,  0.4272,  0.1301],\n",
       "        [-0.8083, -0.8821, -0.7240,  0.4036],\n",
       "        [ 0.0889,  0.8781,  0.5878, -0.9667]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 损失函数\n",
    "损失函数用于衡量模型的预测值与真实值之间的差异。\n",
    "\n",
    "常见的损失函数包括：\n",
    "\n",
    "* 均方误差（MSELoss）：回归问题常用，计算输出与目标值的平方差。\n",
    "* 交叉熵损失（CrossEntropyLoss）：分类问题常用，计算输出和真实标签之间的交叉熵。\n",
    "* BCEWithLogitsLoss：二分类问题，结合了 Sigmoid 激活和二元交叉熵损失。"
   ],
   "id": "6001c11b4c017859"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:55:33.510409Z",
     "start_time": "2025-08-19T08:55:33.497595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 均方误差\n",
    "criterion = nn.MSELoss()\n",
    "criterion"
   ],
   "id": "77a9108dba12b0b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:56:17.651789Z",
     "start_time": "2025-08-19T08:56:17.643787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 交叉熵损失\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion"
   ],
   "id": "c076efeceed9ef7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T08:57:08.818062Z",
     "start_time": "2025-08-19T08:57:08.808572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 二分类交叉熵损失\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion"
   ],
   "id": "82b2fdbb4dd5a032",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 优化器\n",
    "优化器负责在训练过程中更新网络权重和偏置\n",
    "常见的优化器包括：\n",
    "* SGD（随机梯度下降）\n",
    "* Adam（自适应矩估计）\n",
    "* RMSprop（均方根传播）"
   ],
   "id": "8b90ccacb17440f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:55:44.754788Z",
     "start_time": "2025-08-19T09:55:44.024736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "# 使用 SGD 优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 使用 Adam 优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "cc362255856dc091",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 训练神经网络的过程\n",
    "1. 准备数据，通 DataLoader 加载数据\n",
    "2. 定义损失函数和优化器\n",
    "3. 前向传播：计算模型的输出\n",
    "4. 计算损失：与目标值比较，得到损失值\n",
    "5. 反向传播：计算梯度 loss.backward()\n",
    "6. 更新参数：通过 optimizer.step() 更新模型的参数\n",
    "7. 重复上述步骤，直到达到预定的训练轮数"
   ],
   "id": "787d5517a2681ca6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:55:48.040441Z",
     "start_time": "2025-08-19T09:55:47.837967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10 个样本，每个样本有 2 个特征\n",
    "X = torch.randn(10, 2)\n",
    "# 10 个目标标签\n",
    "Y = torch.randn(10, 1)\n",
    "# 训练过程\n",
    "for epoch in range(100):\n",
    "    # 设置训练模式\n",
    "    model.train()\n",
    "    # 清楚梯度\n",
    "    optimizer.zero_grad()\n",
    "    # 前向传播\n",
    "    output = model(X)\n",
    "    # 计算损失\n",
    "    loss = criterion(output, Y)\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "     # 更新权重\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:  # 每 10 轮输出一次损失\n",
    "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')\n"
   ],
   "id": "cde6c3f1db0e82ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.8294\n",
      "Epoch [20/100], Loss: 0.8215\n",
      "Epoch [30/100], Loss: 0.8136\n",
      "Epoch [40/100], Loss: 0.8057\n",
      "Epoch [50/100], Loss: 0.7978\n",
      "Epoch [60/100], Loss: 0.7899\n",
      "Epoch [70/100], Loss: 0.7819\n",
      "Epoch [80/100], Loss: 0.7735\n",
      "Epoch [90/100], Loss: 0.7646\n",
      "Epoch [100/100], Loss: 0.7554\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 测试与评估\n",
    "训练完成后，需要对模型进行测试和评估。\n",
    "\n",
    "常见的步骤包括：\n",
    "\n",
    "计算测试集的损失：测试模型在未见过的数据上的表现。\n",
    "计算准确率（Accuracy）：对于分类问题，计算正确预测的比例。\n"
   ],
   "id": "13922781066108ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T10:00:01.576038Z",
     "start_time": "2025-08-19T10:00:01.565493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假设你有测试集 X_test 和 Y_test\n",
    "X_test = torch.randn(10, 2)\n",
    "Y_test = torch.randn(10, 1)\n",
    "model.eval()  # 设置模型为评估模式\n",
    "with torch.no_grad():  # 在评估过程中禁用梯度计算\n",
    "    output = model(X_test)\n",
    "    loss = criterion(output, Y_test)\n",
    "    print(f'Test Loss: {loss.item():.4f}')"
   ],
   "id": "2edd4bc4386d218b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7610\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 神经网络类型\n",
    "1. 前馈神经网络（Feedforward Neural Networks）：数据单向流动，从输入层到输出层，无反馈连接。\n",
    "2. 卷积神经网络（Convolutional Neural Networks, CNNs）：适用于图像处理，使用卷积层提取空间特征。\n",
    "3. 循环神经网络（Recurrent Neural Networks, RNNs）：适用于序列数据，如时间序列分析和自然语言处理，允许信息反馈循环。\n",
    "4. 长短期记忆网络（Long Short-Term Memory, LSTM）：一种特殊的RNN，能够学习长期依赖关系。"
   ],
   "id": "9ac9539c50ccf791"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
